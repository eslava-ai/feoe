# Script de ExtracciÃ³n de Empresas FCT

Este script automatiza la extracciÃ³n de datos de empresas del sistema SAÃ“ FCT de la Generalitat Valenciana para gestionar las prÃ¡cticas de alumnos.

## ğŸš€ CaracterÃ­sticas

- âœ… Login automÃ¡tico con credenciales seguras
- âœ… ExtracciÃ³n del listado principal de empresas
- âœ… ObtenciÃ³n de datos detallados de cada empresa
- âœ… ExportaciÃ³n a JSON con timestamp
- âœ… Logging completo y manejo de errores
- âœ… Screenshots automÃ¡ticos en caso de error
- âœ… ConfiguraciÃ³n headless opcional

## ğŸ“‹ Datos ExtraÃ­dos

### Del listado principal:
- ID de empresa
- Fecha de registro
- Ãšltimo acceso

### De cada pÃ¡gina de detalle:
- CIF
- Nombre
- DirecciÃ³n
- Provincia
- Localidad
- CÃ³digo postal
- TelÃ©fono
- Fax
- Actividad
- Nombre del gerente
- NIF del gerente
- Email
- Tipo

## ğŸ› ï¸ InstalaciÃ³n

### 1. Clonar el repositorio
```bash
git clone <url-del-repositorio>
cd feoe
```

### 2. Crear entorno virtual
```bash
python -m venv venv
```

### 3. Activar entorno virtual

**Windows:**
```bash
venv\Scripts\activate
```

**Linux/Mac:**
```bash
source venv/bin/activate
```

### 4. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 5. Configurar credenciales
```bash
# Copiar plantilla de credenciales
copy .env.example .env

# Editar .env con tus credenciales reales
notepad .env
```

Rellena el archivo `.env` con tus credenciales:
```
SAO_USUARIO=tu_usuario_aqui
SAO_PASSWORD=tu_contraseÃ±a_aqui
```

## ğŸš€ Uso

### EjecuciÃ³n bÃ¡sica
```bash
python scraper.py
```

### EjecuciÃ³n en modo headless (sin interfaz grÃ¡fica)
Edita `scraper.py` y cambia:
```python
scraper = SAOScraper(headless=True)
```

## ğŸ“ Estructura del Proyecto

```
feoe/
â”œâ”€â”€ .env                    # Credenciales (NO se sube a Git)
â”œâ”€â”€ .env.example           # Plantilla de credenciales
â”œâ”€â”€ .gitignore             # Archivos ignorados por Git
â”œâ”€â”€ requirements.txt       # Dependencias Python
â”œâ”€â”€ models.py              # Modelos de datos
â”œâ”€â”€ scraper.py             # Script principal
â”œâ”€â”€ README.md              # Este archivo
â”œâ”€â”€ output/                # Archivos JSON generados
â”‚   â””â”€â”€ empresas_YYYYMMDD_HHMMSS.json
â””â”€â”€ scraper.log            # Log de ejecuciÃ³n
```

## ğŸ“Š Archivos de Salida

El script genera archivos JSON con la siguiente estructura:

```json
{
  "metadata": {
    "timestamp": "2024-01-15T10:30:00",
    "total_empresas": 150,
    "errores": 2,
    "tiempo_total": "0:05:30"
  },
  "empresas": [
    {
      "id_empresa": "67331",
      "registrado": "2023-01-15",
      "ultimo_acceso": "2024-01-10",
      "cif": "A12345678",
      "nombre": "Empresa Ejemplo S.L.",
      "direccion": "Calle Principal 123",
      "provincia": "Valencia",
      "localidad": "Valencia",
      "cp": "46001",
      "telefono": "963123456",
      "fax": "963123457",
      "actividad": "TecnologÃ­a",
      "nombre_gerente": "Juan PÃ©rez",
      "nif_gerente": "12345678A",
      "email": "contacto@empresa.com",
      "tipo": "PYME"
    }
  ]
}
```

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Ajustar selectores HTML
Tras la primera ejecuciÃ³n, es posible que necesites ajustar los selectores en `scraper.py`:

1. **Login**: Ajusta los nombres de los campos de usuario y contraseÃ±a
2. **Listado**: Modifica el selector de la tabla de empresas
3. **Detalles**: Ajusta los XPath para extraer campos especÃ­ficos

### Modificar delays
```python
# En scraper.py, lÃ­nea ~200
time.sleep(0.5)  # Cambiar delay entre peticiones
```

### Configurar timeouts
```python
# En scraper.py, lÃ­nea ~50
self.wait = WebDriverWait(self.driver, 10)  # Cambiar timeout
```

## ğŸ”’ Seguridad

- âœ… Las credenciales se almacenan en `.env` (no se sube a Git)
- âœ… El archivo `.env` estÃ¡ en `.gitignore`
- âœ… Usa variables de entorno para credenciales
- âœ… Logs no contienen informaciÃ³n sensible

## ğŸ› SoluciÃ³n de Problemas

### Error: "Credenciales no encontradas"
- Verifica que el archivo `.env` existe
- Comprueba que las variables `SAO_USUARIO` y `SAO_PASSWORD` estÃ¡n definidas

### Error: "ChromeDriver no encontrado"
- El script descarga automÃ¡ticamente ChromeDriver
- Verifica tu conexiÃ³n a internet

### Error: "Elemento no encontrado"
- Los selectores HTML pueden haber cambiado
- Revisa `scraper.log` para mÃ¡s detalles
- Ajusta los selectores en `scraper.py`

### Error de login
- Verifica que las credenciales son correctas
- Comprueba que el sistema SAÃ“ FCT estÃ¡ disponible
- Revisa si hay captcha o verificaciÃ³n adicional

## ğŸ“ Logs

El script genera logs en `scraper.log` con informaciÃ³n detallada:
- Progreso de extracciÃ³n
- Errores especÃ­ficos
- Tiempo de ejecuciÃ³n
- Screenshots automÃ¡ticos en caso de error

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -am 'AÃ±adir nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## âš ï¸ Aviso Legal

Este script es para uso educativo y de gestiÃ³n interna. AsegÃºrate de cumplir con:
- TÃ©rminos de uso del sistema SAÃ“ FCT
- PolÃ­ticas de la Generalitat Valenciana
- LegislaciÃ³n de protecciÃ³n de datos (RGPD)

## ğŸ“ Soporte

Si encuentras problemas:
1. Revisa los logs en `scraper.log`
2. Verifica la configuraciÃ³n de credenciales
3. Comprueba que el sistema SAÃ“ FCT estÃ¡ disponible
4. Abre un issue en el repositorio con detalles del error

